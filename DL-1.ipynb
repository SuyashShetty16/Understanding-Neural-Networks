{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPnX2BcIKZwmBzGH1YuXiFA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":55,"metadata":{"id":"N99J4jofPEB2","executionInfo":{"status":"ok","timestamp":1707731096390,"user_tz":-330,"elapsed":529,"user":{"displayName":"Harish Shetty","userId":"17442190090347993059"}}},"outputs":[],"source":["import numpy as np\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","source":["# Perceptron Class with Activation Function Support\n","class Perceptron(object):\n","    def __init__(self, Learn_Rate=0.01, Iterations=10, activation='sigmoid'):\n","        self.learn_rate = Learn_Rate\n","        self.Iterations = Iterations\n","        self.activation_name = activation\n","        self.activation_func, self.activation_func_derivative = self._get_activation_function(activation)\n","        self.errors = []\n","        self.weights = None\n","\n","    def _get_activation_function(self, name):\n","        if name == 'sigmoid':\n","            return (lambda x: 1 / (1 + np.exp(-x)), lambda x: x * (1 - x))\n","        elif name == 'relu':\n","            return (lambda x: np.maximum(0, x), lambda x: np.where(x <= 0, 0, 1))\n","        elif name == 'tanh':\n","            return (lambda x: np.tanh(x), lambda x: 1 - x**2)\n","        else:\n","            raise ValueError(f\"Unsupported activation function: {name}\")\n","\n","    def fit(self, x, y):\n","        self.weights = np.zeros(1 + x.shape[1])\n","        for _ in range(self.Iterations):\n","            error = 0\n","            for xi, target in zip(x, y):\n","                linear_output = np.dot(xi, self.weights[1:]) + self.weights[0]\n","                activated_output = self.activation_func(linear_output)\n","                update = self.learn_rate * (target - activated_output)\n","                self.weights[1:] += update * xi\n","                self.weights[0] += update\n","                error += int(update != 0.0)\n","            self.errors.append(error)\n","        return self\n","\n","    def net_input(self, x):\n","        return np.dot(x, self.weights[1:]) + self.weights[0]\n","\n","    def predict(self, x):\n","        linear_output = self.net_input(x)\n","        activated_output = self.activation_func(linear_output)\n","        return np.where(activated_output >= 0.5, 1, -1)"],"metadata":{"id":"Tf_pr5zkPIFX","executionInfo":{"status":"ok","timestamp":1707731117490,"user_tz":-330,"elapsed":556,"user":{"displayName":"Harish Shetty","userId":"17442190090347993059"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["# Data Preparation\n","iris = load_iris()\n","X = iris.data[:100, [0, 2]]\n","y = iris.target[:100]\n","y = np.where(y == 0, -1, 1)"],"metadata":{"id":"o3U0G-vOPLkW","executionInfo":{"status":"ok","timestamp":1707731135440,"user_tz":-330,"elapsed":727,"user":{"displayName":"Harish Shetty","userId":"17442190090347993059"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["# Splitting the dataset into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"HkbUfLA_POUL","executionInfo":{"status":"ok","timestamp":1707731155093,"user_tz":-330,"elapsed":614,"user":{"displayName":"Harish Shetty","userId":"17442190090347993059"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["# Training and Evaluating Perceptron with Different Activation Functions\n","activation_functions = ['sigmoid', 'relu', 'tanh']\n","accuracies = []\n","\n","for activation in activation_functions:\n","    classifier = Perceptron(Learn_Rate=0.01, Iterations=10, activation=activation)\n","    classifier.fit(X_train, y_train)\n","    y_pred = classifier.predict(X_test)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    accuracies.append(accuracy)"],"metadata":{"id":"hSk5psG7Pm4a","executionInfo":{"status":"ok","timestamp":1707731179427,"user_tz":-330,"elapsed":529,"user":{"displayName":"Harish Shetty","userId":"17442190090347993059"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["# Displaying accuracies\n","for activation, accuracy in zip(activation_functions, accuracies):\n","    print(f'Accuracy with {activation.capitalize()} activation function: {accuracy}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"en9ns_OFPpuW","executionInfo":{"status":"ok","timestamp":1707731207174,"user_tz":-330,"elapsed":550,"user":{"displayName":"Harish Shetty","userId":"17442190090347993059"}},"outputId":"ab89b24e-6f1d-4af6-f451-ab6f4bf8913f"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy with Sigmoid activation function: 1.0\n","Accuracy with Relu activation function: 0.95\n","Accuracy with Tanh activation function: 1.0\n"]}]}]}